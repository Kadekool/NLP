{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kKEU8GJiD053"
      },
      "outputs": [],
      "source": [
        "# trainData\n",
        "\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib import request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyrwfTgDD058",
        "outputId": "c2c8fe79-f93b-4e64-c7d1-0bd7c17e2b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\n"
          ]
        }
      ],
      "source": [
        "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\n",
        "module_name = module_url.split('/')[-1]\n",
        "print(f'Fetching {module_url}')\n",
        "# with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
        "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
        "    a = f.read()\n",
        "    outf.write(a.decode('utf-8'))\n",
        "# dfTrain = pd.DataFrame(trainData, columns = ['','Word','Tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tOHlZdOhD059"
      },
      "outputs": [],
      "source": [
        "from dont_patronize_me import DontPatronizeMe\n",
        "# Initialize a dpm (Don't Patronize Me) object.\n",
        "# It takes two areguments as input: \n",
        "# (1) Path to the directory containing the training set files, which is the root directory of this notebook.\n",
        "# (2) Path to the test set, which will be released when the evaluation phase begins. In this example, \n",
        "# we use the dataset for Subtask 1, which the code will load without labels.\n",
        "dpm = DontPatronizeMe('.', 'dontpatronizeme_pcl.tsv')\n",
        "# dpm = DontPatronizeMe('/Users/benma/dontpatronizeme_v1.4', 'dontpatronizeme_pcl.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ap9z9g6qD05-"
      },
      "outputs": [],
      "source": [
        "# This method loads the subtask 1 data\n",
        "dpm.load_task1()\n",
        "# which we can then access as a dataframe\n",
        "df = dpm.train_task1_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TE-0E4TsD05-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6898b189-0fc8-43f2-ee2b-06dd780b4a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>par_id</th>\n",
              "      <th>art_id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>orig_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@@24942188</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>ph</td>\n",
              "      <td>we 're living in times of absolute insanity , ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@@21968160</td>\n",
              "      <td>migrant</td>\n",
              "      <td>gh</td>\n",
              "      <td>in libya today , there are countless number of...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@@16584954</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>\"white house press secretary sean spicer said ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>@@7811231</td>\n",
              "      <td>disabled</td>\n",
              "      <td>nz</td>\n",
              "      <td>council customers only signs would be displaye...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>@@1494111</td>\n",
              "      <td>refugee</td>\n",
              "      <td>ca</td>\n",
              "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10464</th>\n",
              "      <td>10465</td>\n",
              "      <td>@@14297363</td>\n",
              "      <td>women</td>\n",
              "      <td>lk</td>\n",
              "      <td>\"sri lankan norms and culture inhibit women fr...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10465</th>\n",
              "      <td>10466</td>\n",
              "      <td>@@70091353</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>ph</td>\n",
              "      <td>he added that the afp will continue to bank on...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10466</th>\n",
              "      <td>10467</td>\n",
              "      <td>@@20282330</td>\n",
              "      <td>in-need</td>\n",
              "      <td>ng</td>\n",
              "      <td>\"\"\" she has one huge platform , and informatio...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10467</th>\n",
              "      <td>10468</td>\n",
              "      <td>@@16753236</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>in</td>\n",
              "      <td>\"\"\" anja ringgren loven i ca n't find a word t...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10468</th>\n",
              "      <td>10469</td>\n",
              "      <td>@@16779383</td>\n",
              "      <td>homeless</td>\n",
              "      <td>ie</td>\n",
              "      <td>\"\"\" guinness world record of 540lbs of 7-layer...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10469 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      par_id      art_id  ... label orig_label\n",
              "0          1  @@24942188  ...     0          0\n",
              "1          2  @@21968160  ...     0          0\n",
              "2          3  @@16584954  ...     0          0\n",
              "3          4   @@7811231  ...     0          0\n",
              "4          5   @@1494111  ...     0          0\n",
              "...      ...         ...  ...   ...        ...\n",
              "10464  10465  @@14297363  ...     0          1\n",
              "10465  10466  @@70091353  ...     0          0\n",
              "10466  10467  @@20282330  ...     1          3\n",
              "10467  10468  @@16753236  ...     1          4\n",
              "10468  10469  @@16779383  ...     1          3\n",
              "\n",
              "[10469 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ONiEh6j6D05_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa26e0ef-161f-40be-9a70-4c6473c28f48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9476\n",
              "1     993\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "aPp6OYtED06A"
      },
      "outputs": [],
      "source": [
        "def labels2file(p, outf_path):\n",
        "    with open(outf_path,'w') as outf:\n",
        "        for pi in p:\n",
        "            outf.write(','.join([str(k) for k in pi])+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gsSEenwiD06A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857ba8f3-39ea-4b72-de3d-0e07396dd8f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜refâ€™: File exists\n",
            "mkdir: cannot create directory â€˜resâ€™: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ref res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "Ajuz44gkD06B"
      },
      "outputs": [],
      "source": [
        "dpm.load_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "n8fzZBH-D06D"
      },
      "outputs": [],
      "source": [
        "preds_task1 = [[random.randint(0,1)] for k in range(0,len(dpm.test_set))]\n",
        "labels2file(preds_task1, os.path.join('res/', 'task1.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "oM7S3VN-D06G"
      },
      "outputs": [],
      "source": [
        "# !pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fbHNSqdGD06H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71b99a6-8f9e-436b-a197-3ca5e2eaf447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "\n",
        "from official.nlp import optimization  # to create AdamW optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DRfmiU9eD06I"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "sRe5OEvAD06J"
      },
      "outputs": [],
      "source": [
        "# bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "PJI5LTjkD06J"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8C3v2bo3D06K"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7ydcDZY7D06K"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#Return the cleaned text\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZjG9eqkiD06L"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "data = list(df['text'])\n",
        "for sen in data:\n",
        "    sentences.append(preprocess_text(sen))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oM1fLCxYD06L"
      },
      "outputs": [],
      "source": [
        "# df = dpm.train_task1_df.head()\n",
        "# print(movie_reviews.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JZix0KpXD06L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d38e79-dff3-439c-e8d4-75129a94dd6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "inrY1WPVD06M"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "#create a BERT embedding layer by importing the BERT model from hub.KerasLayer\n",
        "#trainable parameter is false since we will not further train the model\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "#create a BERT vocabulary file\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "#set the text to lowercase\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "#pass vocabulary_file and to_lower_case to the BertTokenizer object\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "I99hC1nED06M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f92c85f-a6c4-4319-ec0c-49149f0ee029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1045,\n",
              " 2123,\n",
              " 1005,\n",
              " 1056,\n",
              " 2228,\n",
              " 2008,\n",
              " 2017,\n",
              " 1005,\n",
              " 2128,\n",
              " 2583,\n",
              " 2000,\n",
              " 3942,\n",
              " 2888,\n",
              " 1005,\n",
              " 1055,\n",
              " 2160,\n",
              " 1012]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Just to see how this thing tokenizes\n",
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"I don't think that you're able to visit Henry's house.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x70SBbUtD06N"
      },
      "outputs": [],
      "source": [
        "def tokenize_reviews(text_reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sWykt_qbD06N"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences = [tokenize_reviews(sent) for sent in sentences]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "O_ck0y4NYsL1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To see the accuracy and precision as model is training\n",
        "additional_metrics = ['accuracy', tf.keras.metrics.Precision()]\n",
        "\n",
        "# Various parameters I have not really messed with yet\n",
        "batch_size = 512\n",
        "\n",
        "# 10 seems to be a good value for this parameter\n",
        "embedding_output_dims = 10\n",
        "loss_function = BinaryCrossentropy()\n",
        "\n",
        "# Idea of max sequence is to cut off sequence if exceeding certain length\n",
        "# Saves a ton of time on training since longest sequences is 5501 tokens\n",
        "max_sequence_length = 100\n",
        "number_of_epochs = 20\n",
        "\n",
        "# Adam is an optimizer that seems to be very standard that Ive worked with in the past.\n",
        "# I have not looked to see if there are better ones for this case\n",
        "optimizer = Adam()\n",
        "\n",
        "#Parameter just to see info as model is training \n",
        "verbosity_mode = 1\n",
        "\n",
        "# Will want to calculate number of unique words at some point, may be a useful parameter\n",
        "\n",
        "# words = []\n",
        "# for i in range(0,len(x_train)):\n",
        "#   for j in range(0,len(x_train[i])):\n",
        "#     words.append(x_train[i][j])\n",
        "# num_distinct_words = set(words)\n",
        "# max_len = 0\n",
        "# words = []\n",
        "# for i in range(0,len(df['text'][training_idx])):\n",
        "#   if(len(df['text'][i]) > max_len):\n",
        "#     max_len = len(df['text'][i])\n",
        "#   for j in range(0,len(df['text'][i])):\n",
        "#     words.append(df['text'][i][j])\n",
        "\n",
        "# num_distinct_words = set(words)\n",
        "\n",
        "# print(len(num_distinct_words))\n",
        "# print(tokenized_sentences)\n",
        "# print(max_len)"
      ],
      "metadata": {
        "id": "WLAnWMJcZF7o"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JLjJ6cF9nuaG"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to pad inputs with 0 to standardize their lengths\n",
        "padded_inputs = pad_sequences(tokenized_sentences, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>\n",
        "\n",
        "# separate into training and testing sets\n",
        "indices = np.random.permutation(padded_inputs.shape[0])\n",
        "\n",
        "#Roughly a 80/20 split\n",
        "training_idx, test_idx = indices[:8000], indices[8000:]\n",
        "# training_idx, test_idx = indices[2000:], indices[:2000]\n",
        "\n",
        "\n",
        "padded_inputs_train = padded_inputs[training_idx]\n",
        "padded_inputs_test = padded_inputs[test_idx]\n",
        "\n",
        "labels_inputs = df['label'][training_idx]\n"
      ],
      "metadata": {
        "id": "C517UD64a60G"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "\n",
        "\n",
        "# I want to figure out how to do a custom activation function so I dont have to have the code at the end of the notebook that just shifts the decision point\n",
        "\n",
        "\n",
        "# def custom_activation(x):\n",
        "#   val = (K.sigmoid(x) * 10)\n",
        "#   if( val > 1):\n",
        "#     return .99\n",
        "#   else:\n",
        "#     return val\n",
        "# get_custom_objects().update({'custom_activation': Activation(custom_activation)})"
      ],
      "metadata": {
        "id": "VVNbvliuwTmy"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Embedding layer:\n",
        "# This is just to get the model to run. Will want to actually calculate the correct value\n",
        "num_unique_words = 50000\n",
        "model.add(Embedding(30000, embedding_output_dims, input_length=max_sequence_length))\n",
        "\n",
        "\n",
        "# Biderection lstm layer:\n",
        "# Merge mode parameter is \"mode by which outputs of forward and backward RNN will be combined\"\n",
        "# concat seems to be the best one, but I havent tested it extensively yet\n",
        "\n",
        "# Havent messed with dropout rate much either\n",
        "model.add(Bidirectional(LSTM(20, dropout = .3, return_sequences=True)))\n",
        "# model.add(Bidirectional(LSTM(20, dropout = .1, return_sequences=True)))\n",
        "# model.add(Bidirectional(LSTM(20, dropout = .1, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(20, dropout = .3, return_sequences=True)))\n",
        "\n",
        "model.add(Bidirectional(LSTM(20,dropout = .3), merge_mode='concat'))\n",
        "\n",
        "\n",
        "# Will want to try multiple layers, perhaps try a custom backwards layer?\n",
        "\n",
        "\n",
        "# Dense layer with a sigmoid activation function\n",
        "# Outputs as a probability so we can produce the binary classes\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# model.add(Activation(custom_activation, name='SpecialActivation'))\n",
        "# Will want to try different activation function: relu, softmax etc\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)\n",
        "\n",
        "# Give a summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(padded_inputs_train, labels_inputs, validation_data=(padded_inputs_test, df['label'][test_idx]), batch_size=batch_size, epochs=number_of_epochs, verbose=verbosity_mode)\n",
        "\n",
        "# Test the model after training\n",
        "# test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)"
      ],
      "metadata": {
        "id": "DwJ0CjNpYtVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7903939-4109-4ecc-c121-f8e5271a96cb"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_17 (Embedding)    (None, 100, 10)           300000    \n",
            "                                                                 \n",
            " bidirectional_51 (Bidirecti  (None, 100, 40)          4960      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_52 (Bidirecti  (None, 100, 40)          9760      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_53 (Bidirecti  (None, 40)               9760      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 324,521\n",
            "Trainable params: 324,521\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 28s 952ms/step - loss: 0.6071 - accuracy: 0.8516 - precision_10: 0.0654 - val_loss: 0.4164 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 12s 748ms/step - loss: 0.3364 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3187 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 12s 753ms/step - loss: 0.3168 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3117 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 12s 758ms/step - loss: 0.3147 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3107 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 12s 761ms/step - loss: 0.3140 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3104 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.3137 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3100 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.3132 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3095 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 12s 770ms/step - loss: 0.3114 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3073 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 12s 769ms/step - loss: 0.3048 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.3010 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 12s 755ms/step - loss: 0.2781 - accuracy: 0.9047 - precision_10: 0.0000e+00 - val_loss: 0.2763 - val_accuracy: 0.9064 - val_precision_10: 0.0000e+00\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 12s 764ms/step - loss: 0.2131 - accuracy: 0.9082 - precision_10: 0.9375 - val_loss: 0.2687 - val_accuracy: 0.9068 - val_precision_10: 0.5185\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 12s 757ms/step - loss: 0.1383 - accuracy: 0.9526 - precision_10: 0.7960 - val_loss: 0.2910 - val_accuracy: 0.9056 - val_precision_10: 0.4919\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 12s 768ms/step - loss: 0.0891 - accuracy: 0.9712 - precision_10: 0.8725 - val_loss: 0.3247 - val_accuracy: 0.9081 - val_precision_10: 0.5172\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 12s 767ms/step - loss: 0.0624 - accuracy: 0.9819 - precision_10: 0.9175 - val_loss: 0.3312 - val_accuracy: 0.9089 - val_precision_10: 0.5294\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 12s 769ms/step - loss: 0.0449 - accuracy: 0.9883 - precision_10: 0.9465 - val_loss: 0.3775 - val_accuracy: 0.9056 - val_precision_10: 0.4921\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 12s 760ms/step - loss: 0.0344 - accuracy: 0.9909 - precision_10: 0.9575 - val_loss: 0.4070 - val_accuracy: 0.9097 - val_precision_10: 0.5426\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 12s 759ms/step - loss: 0.0228 - accuracy: 0.9950 - precision_10: 0.9750 - val_loss: 0.4338 - val_accuracy: 0.9060 - val_precision_10: 0.4962\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 12s 765ms/step - loss: 0.0192 - accuracy: 0.9958 - precision_10: 0.9802 - val_loss: 0.4497 - val_accuracy: 0.9081 - val_precision_10: 0.5185\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 12s 763ms/step - loss: 0.0175 - accuracy: 0.9960 - precision_10: 0.9790 - val_loss: 0.4836 - val_accuracy: 0.9060 - val_precision_10: 0.4952\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 12s 765ms/step - loss: 0.0145 - accuracy: 0.9970 - precision_10: 0.9855 - val_loss: 0.4988 - val_accuracy: 0.8979 - val_precision_10: 0.4356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training acc', 'testing acc', 'training loss', 'testing loss'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7sfU4R6s2d-h",
        "outputId": "cadb9381-2320-406c-9dc5-c766db762615"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that actually after 5-10 or so epochs, the model is now learning the \"wrong\" things. We can see this from the fact that the accuracy and loss decouple between the training and test sets. The model is able to figure out very precise patterns in the training set that due to randomness are not in the test set. By randomizing the test and training set before training, we've seen that this phenomena happens at different number of epochs"
      ],
      "metadata": {
        "id": "cOa3Hjj9JLeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "du8Qjf4YD06Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0bd51c-fa43-4f99-d271-02b4918da0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.29742295]\n",
            " [0.00137973]\n",
            " [0.98629606]\n",
            " ...\n",
            " [0.00148842]\n",
            " [0.00160012]\n",
            " [0.00144181]]\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(padded_inputs_test)\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "-bWsZv0WD06Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db542ae7-4a6d-443c-be58-f74fb9cf0b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "338 2131\n"
          ]
        }
      ],
      "source": [
        "# See how many positive and negative predictions in test set\n",
        "negCount = 0\n",
        "posCount = 0\n",
        "res = []\n",
        "for i in range(0,len(results)):\n",
        "\n",
        "# I noticed the rate of positives to negatives here was significantly lower than the training set if we used a .5 cuttof\n",
        "# Because of this, I significantly lower the decision point to try and capture more \"true positives\"\n",
        "# This is really just an extension of the activation function we used earlier\n",
        "# The activation function was skewing the results in a way we dont want, so this is effectively \"unskewing\" the results\n",
        "\n",
        "  if(results[i]< .005):\n",
        "    negCount += 1\n",
        "    res.append(0)\n",
        "  else:\n",
        "    posCount += 1\n",
        "    res.append(1)\n",
        "print(posCount,negCount)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_task1 = [[res[k]] for k in range(0,len(res))]\n",
        "\n",
        "labels2file(preds_task1, os.path.join('res/', 'task1.txt'))"
      ],
      "metadata": {
        "id": "6QBsWki4Q-c0"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels2file(dpm.train_task1_df.label[test_idx].apply(lambda x:[x]).tolist(), os.path.join('ref/', 'task1.txt'))"
      ],
      "metadata": {
        "id": "_j6NQNUfTlMl"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import os.path\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# as per the metadata file, input and output directories are the arguments\n",
        "[_, input_dir, output_dir] = sys.argv\n",
        "\n",
        "# unzipped submission data is always in the 'res' subdirectory\n",
        "# https://github.com/codalab/codalab-competitions/wiki/User_Building-a-Scoring-Program-for-a-Competition#directory-structure-for-submissions\n",
        "\n",
        "# define gold data path\n",
        "ref_dir = os.path.join(\".\", 'ref')\n",
        "\n",
        "# define submission data path\n",
        "submission_dir = os.path.join(\".\", 'res')\n",
        "files = os.listdir(submission_dir)\n",
        "\n",
        "# define path for scores file\n",
        "outf = open(os.path.join(\".\",'scores.txt'),'w')\n",
        "\n",
        "# evaluating on task 1\n",
        "if 'task1.txt' in files:\n",
        "    task1_res = []\n",
        "    task1_gold = []\n",
        "    with open(os.path.join(submission_dir,'task1.txt')) as f:\n",
        "        for line in f:\n",
        "            task1_res.append(int(line.strip()))\n",
        "    with open(os.path.join(ref_dir,'task1.txt')) as f:\n",
        "        for line in f:\n",
        "            task1_gold.append(int(line.strip()))\n",
        "    # task 1 scores\n",
        "    t1p = precision_score(task1_gold, task1_res)\n",
        "    t1r = recall_score(task1_gold, task1_res)\n",
        "    t1f = f1_score(task1_gold, task1_res)\n",
        "    # task1\n",
        "    outf.write('task1_precision:'+str(t1p)+'\\n')\n",
        "    outf.write('task1_recall:'+str(t1r)+'\\n')\n",
        "    outf.write('task1_f1:'+str(t1f)+'\\n')    \n",
        "\n",
        "\n",
        "outf.close()"
      ],
      "metadata": {
        "id": "YsczF9MqWQn_"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cOUCt2an1Tjk"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XfM4MywjEAxR"
      },
      "execution_count": 311,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "sharedtask.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}